import streamlit as st  # Streamlit anv√§nds f√∂r att skapa webbaserade datadrivna applikationer i Python.
st.set_page_config(layout="centered") # St√§ller in layouten f√∂r Streamlit-appen till centrerad.
import pandas as pd # Pandas anv√§nds f√∂r att hantera och analysera data i form av tabeller (DataFrames).
import matplotlib.pyplot as plt # Matplotlib √§r ett bibliotek f√∂r att skapa visualiseringar, s√•som grafer och diagram.
import numpy as np # NumPy anv√§nds f√∂r att hantera numeriska operationer och matrisber√§kningar.
import pyodbc # PyODBC anv√§nds f√∂r att ansluta till och interagera med databaser via ODBC-drivrutiner.
import seaborn as sns # Seaborn √§r ett bibliotek som bygger p√• Matplotlib och anv√§nds f√∂r att skapa mer avancerade och snygga visualiseringar.
from wordcloud import WordCloud # WordCloud anv√§nds f√∂r att skapa ordmoln baserat p√• textdata.
from nltk.corpus import stopwords   # NLTK:s stopwords anv√§nds f√∂r att filtrera bort vanliga ord (t.ex. "och", "den", "att") i textanalys.
import nltk # NLTK (Natural Language Toolkit) √§r ett bibliotek f√∂r bearbetning av naturligt spr√•k.
import squarify # Squarify anv√§nds f√∂r att skapa treemap-diagram, en typ av visualisering d√§r rektanglar representerar data.

nltk.download('stopwords')

# --------------------------
# Databasanslutning
# --------------------------


def fetch_data():
    conn = pyodbc.connect(
        "DRIVER={SQL Server};"
        "SERVER=W5CG2241T4M\MSSQLSERVER01;"  # Byt till din SQL Server-instans
        "DATABASE=CloudSQL;"  # Byt till din databas
        "Trust_Connection=yes;"
    )
    query = "SELECT title, content, source_url, published_date, topic, source_news FROM rssnews"
    df = pd.read_sql(query, conn)
    conn.close()

    df['topic'] = df['topic'].fillna('').apply(
        lambda x: [t.strip() for t in x.split(',') if t.strip()])
    df['topic'] = df['topic'].apply(lambda x: x if x else ["Ok√§nd kategori"])
    df['published_date'] = pd.to_datetime(df['published_date'])
    df = df[~df['topic'].apply(lambda x: "Unknown" in x)] # Filtrerar bort "unknown"
    return df

# --------------------------
# Filtreringsfunktion
# --------------------------


def filter_data(data, sources, topics, start_date, end_date, search_term):
    filtered_data = data.copy()
    if sources:
        filtered_data = filtered_data[filtered_data['source_news'].isin(
            sources)]
    if topics:
        filtered_data = filtered_data[filtered_data['topic'].apply(
            lambda t: any(topic in t for topic in topics))]
    filtered_data = filtered_data[(filtered_data['published_date'].dt.date >= start_date) & (
        filtered_data['published_date'].dt.date <= end_date)]
    if search_term:
        filtered_data = filtered_data[filtered_data['title'].str.contains(
            search_term, case=False, na=False)]
    return filtered_data


# --------------------------
# Streamlit UI
# --------------------------
st.title("üì¢ Nyhetsklassificering & Analys")
st.write("Denna app visualiserar RSS-nyhetsdata och dess ML-klassificering.")

data = fetch_data()
filtered_data = data.copy()

with st.sidebar:
    st.subheader("üîç S√∂k & Filtrering")
    all_sources = sorted(data['source_news'].unique())
    all_topics = sorted(
        set(topic for sublist in data["topic"] for topic in sublist))
    selected_sources = st.multiselect(
        "Filtrera efter nyhetsbyr√•:", all_sources)
    selected_topics = st.multiselect("Filtrera efter √§mne:", all_topics)
    start_date = st.date_input("Startdatum", min_value=data['published_date'].min(
    ).date(), value=data['published_date'].min().date())
    end_date = st.date_input("Slutdatum", max_value=data['published_date'].max(
    ).date(), value=data['published_date'].max().date())
    search_term = st.text_input("S√∂k efter artikel:")
    apply_filters = st.button("H√§mta och Filtrera Data")

if apply_filters:
    filtered_data = filter_data(
        data, selected_sources, selected_topics, start_date, end_date, search_term)

st.write(filtered_data)

# --------------------------
# Visualiseringar (alltid synliga)
# --------------------------
with st.container():
    st.markdown("""
    <style>
        .reportview-container .main .block-container{
            max-width: 80%;
            margin: auto;
        }
    </style>
    """, unsafe_allow_html=True)
    st.subheader("üìä Antal artiklar per nyhetsk√§lla")  # 1
source_counts = filtered_data['source_news'].value_counts().reset_index()
source_counts.columns = ['source_news', 'count']
fig, ax = plt.subplots(figsize=(10, 6))
ax.bar(source_counts['source_news'], source_counts['count'], color='skyblue')
ax.set_xticklabels(source_counts['source_news'], rotation=45, ha='right')

st.pyplot(fig)

data_exploded = filtered_data.explode('topic')  # F√∂rbered data

with st.container():
    st.subheader("üìä √Ñmnesf√∂rdelning")  # 2

    # Ber√§kna antal artiklar per √§mne
    topic_counts = data_exploded['topic'].value_counts().reset_index()
    topic_counts.columns = ['√Ñmne', 'Antal']

    # Totalt antal artiklar
    total_articles = topic_counts['Antal'].sum()
    topic_counts['Procent'] = (topic_counts['Antal'] / total_articles) * 100

    # Visa totalen √∂ver treemapen
    st.markdown(f"**Totalt antal artiklar:** {total_articles}")

    # Skapa treemap med squarify
    fig, ax = plt.subplots(figsize=(12, 6))
    colors = plt.cm.Pastel1(np.linspace(0, 1, len(topic_counts)))

    labels = [
        f"{row['√Ñmne']}\n{row['Antal']} ({row['Procent']:.1f}%)" for _, row in topic_counts.iterrows()]

    squarify.plot(sizes=topic_counts['Antal'],
                  label=labels, alpha=0.7, color=colors)

    plt.axis('off')

    st.pyplot(fig)

with st.container():
    st.subheader("üìä Antal artiklar per √§mne")  # 3
topic_counts = data_exploded['topic'].value_counts()
fig, ax = plt.subplots(figsize=(10, 6))
topic_counts.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')
ax.set_xlabel("√Ñmne")
ax.set_ylabel("Antal artiklar")
st.pyplot(fig)

with st.container():
    st.subheader("üìä Antal inl√§gg per kategori och veckodag")  # 4
data_exploded['weekday'] = data_exploded['published_date'].dt.day_name()
pivot = data_exploded.pivot_table(
    index='topic', columns='weekday', aggfunc='size', fill_value=0)
pivot = pivot.reindex(columns=[
                      'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])
fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(pivot, annot=True, fmt=".0f", cmap="Greens", ax=ax)
st.pyplot(fig)

with st.container():
    st.subheader("üìÜ Publiceringar per veckodag")  # 5
weekday_counts = filtered_data['published_date'].dt.day_name().value_counts()
fig, ax = plt.subplots()
weekday_counts.plot(kind='bar', ax=ax, color='salmon', edgecolor='black')
st.pyplot(fig)


from collections import Counter
with st.container():
    st.subheader("‚òÅ Top 15 vanliga ord i nyhetstitlar") #6
swedish_stopwords = set(stopwords.words('swedish')).union({'svar', 'f√•r', 'ska', 'p√•', 'f√∂r', 'att', 'och'})
# Samla in ord fr√•n titlarna som inte finns i stopwords
words = [word.lower() for title in filtered_data['title'] for word in title.split() if word.lower() not in swedish_stopwords]
# R√§kna ordens frekvens och v√§lj de 10 vanligaste
most_common_words = dict(Counter(words).most_common(15))
wordcloud = WordCloud(width=800, height=400, background_color="white").generate_from_frequencies(most_common_words)
fig, ax = plt.subplots()
ax.imshow(wordcloud, interpolation='bilinear')
ax.axis("off")
st.pyplot(fig)

with st.expander("üìå Sammanfattning & Insikter"):
    st.markdown("""
    - **Dagens Nyheter** publicerar flest nyheter - Har de bredare t√§ckning, eller publicerar de fler sm√• nyheter √§n andra?
    - **Samh√§lle och Konflikter** √§r de vanligaste kategorin. - Det s√§ger mycket om vad som prioriteras i media.
    - **Vetenskap och Teknik** har minst antal artiklar, trots att det √§r en av de snabbaste v√§xande och mest inflytesrika sektorerna i v√§rlden.
    - Nyheter publiceras oftast p√• vardagar, **Torsdagar** f√∂r att vara specifik. 
    - Om nyheter publiceras mindre under helger beror det p√• att f√§rre nyheter skrivs, eller att redaktionerna prioriterar andra typer av inneh√•ll?
    - Alla nyhetsk√§llor har samma top 2-√§mnen, men deras tredje st√∂rsta kategori skiljer sig √•t:
    
        **Aftonbladet, Expressen & SVD ‚Üí Livsstil**
        
        **DN, SVT & Sveriges Radio ‚Üí Idrott**
        
        Vilket betyder att det vi uppfattar som "de viktigaste nyheterna" p√•verkas av vilken nyhetsk√§lla vi f√∂ljer.
    """, unsafe_allow_html=True)
